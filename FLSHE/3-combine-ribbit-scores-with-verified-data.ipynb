{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine ribbit scores with verified data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook combines the csv file with ribbit scores with csv files with manually verified data to allow the user to assess the validity of the RIBBIT model. This example is given with the ribbit scores created from all of the data in Dec 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the file setup_functions.ipynb to define setting, import packages, and define functions \n",
    "%run ../ribbit_functions/setup_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define file and folder paths for data import and cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path to csv file with ribbit scores \n",
    "ribbit_scores_fp = \"./results_Dec2022/ribbit_scores_combined.csv\" #*# change this to the file path for your ribbit scores\n",
    "\n",
    "# file path to csv file with manually verified data \n",
    "verified_data_fp = \"./verified_flshe/verified_flshe.csv\" #*# chenge this to the file path for your manually verified data\n",
    "\n",
    "# path to folder that contained the audio files WHEN THE MODEL WAS RUN. If you don't remember, check the ribbit score csv file. The first column has the file paths\n",
    "# Basically the prefix to the audio files - this is used to access the indices of the csv file containing the ribbit scores. \n",
    "audio_files_fp = '/Volumes/Expansion/Frog Call Project/Calling Data/FLSHE/' #*# change this to the file path for where the audio data was WHEN THE MODEL WAS RUN\n",
    "# Note: if the folders within this folder are structured differently, you may need to edit the full file paths in the \n",
    "#       data cleaning section below (inicated with #*#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean RIBBIT score data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ribbit scores based on ribbit_scores_fp\n",
    "rs_flshe = pd.read_csv(ribbit_scores_fp, index_col = 0)\n",
    "\n",
    "rs_flshe['date']=pd.to_datetime(rs_flshe['date']) # convert column to date-time format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean manually verified data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import manually verified data \n",
    "verified_flshe = pd.read_csv(verified_data_fp)[[\"File name\", \"Pond #\", \"L. capito\", \"gopher call time\", \"Date\"]] # keeps only listed columns \n",
    "\n",
    "# rename columns for convenience\n",
    "verified_flshe = verified_flshe.rename(columns = {\"File name\":\"file_name\", \"Pond #\":\"logger\", \"L. capito\":\"Lcapito\", \"gopher call time\":\"call_time\", \"Date\":\"date\"})\n",
    "\n",
    "# make Lcapito categorical\n",
    "verified_flshe.Lcapito = verified_flshe.Lcapito.astype(\"category\")\n",
    "\n",
    "# create year column based on date string\n",
    "verified_flshe['year'] = verified_flshe.date.str[0:4]\n",
    "verified_flshe.astype({\"year\":\"int\"})\n",
    "\n",
    "# add .wav to file name if it is not included with the file name \n",
    "for i in verified_flshe.index:\n",
    "    if verified_flshe[\"file_name\"][i][-4:] != \".wav\": \n",
    "        verified_flshe[\"file_name\"][i] = verified_flshe[\"file_name\"][i] + \".wav\"\n",
    "    \n",
    "#*# create full file path from file names, year, and logger numbers #*# \n",
    "verified_flshe['file_path'] = audio_files_fp + 'FLSHE_' + \\\n",
    "    verified_flshe['year'].astype('string') + \\\n",
    "    '/FLSHE_' + verified_flshe['year'].astype('string') + '_' + verified_flshe['logger'].astype('string') + '/' + \\\n",
    "    verified_flshe['file_name'] #*#\n",
    "\n",
    "# set file path as index \n",
    "verified_flshe = verified_flshe.set_index('file_path')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge ribbit scores to manually verified data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with ribbit scores data file \n",
    "verified_flshe = verified_flshe.drop(columns = [\"year\", \"date\", \"logger\"]).merge(rs_flshe, left_index = True, right_index = True)\n",
    "verified_flshe = verified_flshe.dropna(subset=['Lcapito']) # drop any rows with \"NaN\" for Lcapito - if left empty, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_flshe.to_csv(\"ribbit_scores_with_verified_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSoundscape060",
   "language": "python",
   "name": "opensoundscape060"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
