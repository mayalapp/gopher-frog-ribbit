{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine ribbit scores with verified data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook combines the csv file with ribbit scores with csv files with manually verified data to allow the user to assess the validity of the RIBBIT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the file setup_functions.ipynb to define setting, import packages, and define functions \n",
    "%run ../ribbit_functions/setup_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to combine multiple manually verified data files into one \n",
    "# Data must have the following columns: \"Site\", \"Logger\", \"Sample Date\", \"Species\", \"NAAMP\", \"File ID\"\n",
    "if input(\"Are you sure you want to run this? (type 'yes' to continue)\")=='yes':\n",
    "    folder_path = \"../manually_verified_data/ichaway_verified_data/\"\n",
    "    raw_ich = combine_csvs(folder_path, new_csv_name = \"ichaway_verified_data.csv\")\n",
    "else:\n",
    "    print('aborted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and clean data\n",
    "### Define file and folder paths for data import and cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path to csv file with ribbit scores \n",
    "ribbit_scores_fp = \"./ribbit_scores_Dec2022/ribbit_scores_combined.csv\" #*# change this to file path for ribbit scores\n",
    "\n",
    "# file path to csv file with manually verified data \n",
    "verified_data_fp = \"./ichaway_verified_data/ichaway_verified_data.csv\" #*# change this to file path for verified files\n",
    "\n",
    "# path to folder that contained the audio files WHEN THE MODEL WAS RUN\n",
    "# Basically the prefix to the audio files - this is used to access the indices of the csv file containing the ribbit scores. \n",
    "audio_files_fp = '/Volumes/Expansion/Frog Call Project/Calling Data/ichaway/' #*# change this to file path for where the audio data was WHEN THE MODEL WAS RUN \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean ribbit score data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ribbit scores based on ribbit_scores_fp\n",
    "rs_ich = pd.read_csv(ribbit_scores_fp, index_col = 0)\n",
    "\n",
    "rs_ich['date']=pd.to_datetime(rs_ich['date']) # convert column to date-time format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean manually verfied data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import manually verified data\n",
    "raw_ich = pd.read_csv(verified_data_fp)[[\"Site\", \"Logger\", \"Sample Date\", \"Species\", \"NAAMP\", \"File ID\", \"Start Date\"]]\n",
    "\n",
    "# rename columns for convenience\n",
    "raw_ich = raw_ich.rename(columns = {\"Site\":\"site\", \"Logger\":\"logger\", \"Sample Date\":\"date\", \"Species\":\"species\", \"File ID\":\"file_name\", \"Start Date\":\"folder_date\"})\n",
    "\n",
    "# create year column based on date string\n",
    "raw_ich['year'] = raw_ich.date.astype(str).str[-4:]\n",
    "raw_ich.astype({\"year\":\"int\"})\n",
    "\n",
    "\n",
    "# create full file path from file names and logger numbers \n",
    "raw_ich['folder_date'] = pd.to_datetime(raw_ich['folder_date'], format='%m/%d/%Y').dt.strftime('%-m-%-d-%y')\n",
    "raw_ich['file_path'] = audio_files_fp + 'ichaway_' + raw_ich['year'].astype('string') + '/' + raw_ich['logger'].astype('string') + 'a/' + raw_ich['folder_date'] + '/' + raw_ich['file_name'] + '.wav' #*#\n",
    "# set file path as index \n",
    "raw_ich = raw_ich.set_index('file_path')\n",
    "\n",
    "# identify which rows are Lcapito observations \n",
    "raw_ich['Lcapito'] = raw_ich['species'] == 'LICAP'\n",
    "raw_ich['Lcapito'] = raw_ich['Lcapito'].astype('category')\n",
    "\n",
    "# create \"verified_ich\" dataframe with one row per file with a column (Lcapito) with 1 if the file has a Lcapito and 0 if it does not\n",
    "verified_ich = raw_ich.sort_values([\"file_path\", \"Lcapito\"], ascending = False).groupby('file_path').head(1) \n",
    "\n",
    "# these files were labeled incorrectly in the ichaway data - there are gopher frogs in them \n",
    "# logger 5a: \n",
    "#20150205_194700\n",
    "#20150205_204700\n",
    "#20150205_214700\n",
    "\n",
    "# fix these mistakes\n",
    "temp = audio_files_fp + 'ichaway_2015/5a/2-2-15/20150205_'\n",
    "incorrect_files =  [temp + '194700.wav', temp + '204700.wav', temp + '214700.wav']\n",
    "verified_ich.loc[verified_ich.index.isin(incorrect_files),'Lcapito'] = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge ribbit data and verified data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge option 1 \n",
    "\n",
    "# merge with ribbit scores based on file path\n",
    "# this drops some files where the file path minutes don't match between the rs_ich and verified_ich\n",
    "verified_ich = verified_ich.drop(columns = [\"year\", \"date\", \"logger\"]).merge(rs_ich, left_index = True, right_index = True)\n",
    "verified_ich = verified_ich.dropna(subset=['Lcapito']) # drop any rows with \"NaN\" for Lcapito - if data was entered incorrectly, empty, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge option 2 - better but more likely to cause problems \n",
    "\n",
    "# merge with ribbit scores based on hour of file path (ignore minutes - these sometimes don't match for some reason)\n",
    "# still drops some files but not as many \n",
    "# warning: potential to match incorrect files (e.g. if one file is labeled 10:01 and another 10:58)\n",
    "#rs_ich[\"fp_shortened\"] = rs_ich.index.str[:-8]\n",
    "#verified_ich[\"fp_shortened\"] = verified_ich.index.str[:-8]\n",
    "#verified_ich = verified_ich.drop(columns = [\"year\", \"date\", \"logger\"]).merge(rs_ich, left_on = \"fp_shortened\", right_on = \"fp_shortened\")\n",
    "#verified_ich = verified_ich.dropna(subset=['Lcapito']).drop(columns = [\"fp_shortened\"]) # drop any rows with \"NaN\" for Lcapito - if data was entered incorrectly, empty, etc. \n",
    "\n",
    "### TODO:  still losing some files after merging using this option - why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `get_top_rs()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`def get_top_rs(df, n = 5, min_score = 0.0, t_unit = \"Y\", \\\n",
    "               group_col = 'no_groups', groups = [\"0\"], \\\n",
    "               score_col = \"score\", time_stamp_col = \"time_stamp\", \\\n",
    "               save_csv = False):`\n",
    "\n",
    "**Purpose:** get list of audio files with top ribbit scores for certain criterion\n",
    "\n",
    "**Input:** \n",
    "* `df` - data frame with ribbit scores \n",
    "* `n` - number of files per group (e.g. n = 5 gets top 5 ribbit scores per group)\n",
    "* `min_score` - minimum ribbit score needed for file to be included \n",
    "      (e.g. if you want all files above a ribbit score of 50, you could have min_score = 50 and n = 999999999999)\n",
    "* `t_unit` - unit for how often we want the top scores (options: D, W, M, Y, Q - day, week, month, year, quarter year)\n",
    "* `group_col` - the name of the column with the labels grouping our files \n",
    "      (e.g. \"pond\" for sandhills or \"site\" for ichaway wetlands)\n",
    "* `groups` - list of the groupings \n",
    "      (e.g. for sandhills the pond numbers [398, 399, 400, 401, 402, 403]; for ichaway would be the wetlands' names)\n",
    "* `score_col` - column name where ribbit score is stored \n",
    "* `time_stamp_col` - column name where time stamp for ribbit score is stored\n",
    "* `save_csv` - False if we do not want to save our output to a csv. Otherwise string of the file path where we want to save the csv file \n",
    "      (e.g. \"./ribbit_scores/top_ribbit_scores_per_year.csv\")\n",
    "\n",
    "**Out:**\n",
    "dataframe with top `n` files with ribbit score over `min_score` for each `groups` for every `t_unit` \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable of all ichaway wetlands that had audio loggers \n",
    "ichaway_wetlands = verified_ich['site'].unique()\n",
    "\n",
    "# Get top 3 audio files for each wetland and save it to a csv file\n",
    "temp = get_top_rs(verified_ich, n = 3, group_col = 'site', groups = ichaway_wetlands, save_csv = \"./example_top_rs_ichaway.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSoundscape060",
   "language": "python",
   "name": "opensoundscape060"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
