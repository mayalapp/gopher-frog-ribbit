{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine ribbit scores with verified data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook combines the csv file with ribbit scores with csv files with manually verified data to allow the user to assess the validity of the RIBBIT model. This example is given with the ribbit scores created from all of the data in Dec 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the file setup_functions.ipynb to define setting, import packages, and define functions \n",
    "%run ../ribbit_functions/setup_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to combine multiple manually verified data files into one \n",
    "# Data must have the following columns: \"Site\", \"Logger\", \"Sample Date\", \"Species\", \"NAAMP\", \"File ID\"\n",
    "if input(\"Are you sure you want to run this? (type 'yes' to continue)\")=='yes':\n",
    "    folder_path = \"../manually_verified_data/ichaway_verified_data/\"\n",
    "    raw_ich = combine_csvs(folder_path, new_csv_name = \"ichaway_verified_data.csv\")\n",
    "else:\n",
    "    print('aborted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and clean data\n",
    "### Define file and folder paths for data import and cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path to csv file with ribbit scores \n",
    "ribbit_scores_fp = \"./results_Dec2022/ribbit_scores_combined.csv\" #*# change this to file path for ribbit scores\n",
    "\n",
    "# file path to csv file with manually verified data \n",
    "verified_data_fp = \"./ichaway_verified_data/ichaway_verified_data.csv\" #*# change this to file path for verified files\n",
    "\n",
    "# path to folder that contained the audio files WHEN THE MODEL WAS RUN. If you don't remember, check the ribbit score csv file. The first column has the file paths\n",
    "# Basically the prefix to the audio files - this is used to access the indices of the csv file containing the ribbit scores. \n",
    "audio_files_fp = '/Volumes/Expansion/Frog Call Project/Calling Data/ichaway/' #*# change this to file path for where the audio data was WHEN THE MODEL WAS RUN \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean ribbit score data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ribbit scores based on ribbit_scores_fp\n",
    "rs_ich = pd.read_csv(ribbit_scores_fp, index_col = 0)\n",
    "\n",
    "rs_ich['date']=pd.to_datetime(rs_ich['date']) # convert column to date-time format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean manually verfied data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import manually verified data\n",
    "raw_ich = pd.read_csv(verified_data_fp)[[\"Site\", \"Logger\", \"Sample Date\", \"Species\", \"NAAMP\", \"File ID\", \"Start Date\"]]\n",
    "\n",
    "# rename columns for convenience\n",
    "raw_ich = raw_ich.rename(columns = {\"Site\":\"site\", \"Logger\":\"logger\", \"Sample Date\":\"date\", \"Species\":\"species\", \"File ID\":\"file_name\", \"Start Date\":\"folder_date\"})\n",
    "\n",
    "# create year column based on date string\n",
    "raw_ich['year'] = raw_ich.date.astype(str).str[-4:]\n",
    "raw_ich.astype({\"year\":\"int\"})\n",
    "\n",
    "\n",
    "# create full file path from file names and logger numbers \n",
    "raw_ich['folder_date'] = pd.to_datetime(raw_ich['folder_date'], format='%m/%d/%Y').dt.strftime('%-m-%-d-%y')\n",
    "raw_ich['file_path'] = audio_files_fp + 'ichaway_' + raw_ich['year'].astype('string') + '/' + raw_ich['logger'].astype('string') + 'a/' + raw_ich['folder_date'] + '/' + raw_ich['file_name'] + '.wav' #*#\n",
    "# set file path as index \n",
    "raw_ich = raw_ich.set_index('file_path')\n",
    "\n",
    "# identify which rows are Lcapito observations \n",
    "raw_ich['Lcapito'] = raw_ich['species'] == 'LICAP'\n",
    "raw_ich['Lcapito'] = raw_ich['Lcapito'].astype('category')\n",
    "\n",
    "# create \"verified_ich\" dataframe with one row per file with a column (Lcapito) with 1 if the file has a Lcapito and 0 if it does not\n",
    "verified_ich = raw_ich.sort_values([\"file_path\", \"Lcapito\"], ascending = False).groupby('file_path').head(1) \n",
    "\n",
    "# these files were labeled incorrectly in the ichaway data - there are gopher frogs in them \n",
    "# logger 5a: \n",
    "#20150205_194700\n",
    "#20150205_204700\n",
    "#20150205_214700\n",
    "\n",
    "# fix these mistakes\n",
    "temp = audio_files_fp + 'ichaway_2015/5a/2-2-15/20150205_'\n",
    "incorrect_files =  [temp + '194700.wav', temp + '204700.wav', temp + '214700.wav']\n",
    "verified_ich.loc[verified_ich.index.isin(incorrect_files),'Lcapito'] = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge ribbit data and verified data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge option 1 \n",
    "\n",
    "# merge with ribbit scores based on file path\n",
    "# this drops some files where the file path minutes don't match between the rs_ich and verified_ich\n",
    "verified_ich = verified_ich.drop(columns = [\"year\", \"date\", \"logger\", \"species\"]).merge(rs_ich, left_index = True, right_index = True)\n",
    "verified_ich = verified_ich.dropna(subset=['Lcapito']) # drop any rows with \"NaN\" for Lcapito - if data was entered incorrectly, empty, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge option 2 - better but more likely to cause problems \n",
    "\n",
    "# merge with ribbit scores based on hour of file path (ignore minutes - these sometimes don't match for some reason)\n",
    "# still drops some files but not as many \n",
    "# warning: potential to match incorrect files (e.g. if one file is labeled 10:01 and another 10:58)\n",
    "#rs_ich[\"fp_shortened\"] = rs_ich.index.str[:-8]\n",
    "#verified_ich[\"fp_shortened\"] = verified_ich.index.str[:-8]\n",
    "#verified_ich = verified_ich.drop(columns = [\"year\", \"date\", \"logger\"]).merge(rs_ich, left_on = \"fp_shortened\", right_on = \"fp_shortened\")\n",
    "#verified_ich = verified_ich.dropna(subset=['Lcapito']).drop(columns = [\"fp_shortened\"]) # drop any rows with \"NaN\" for Lcapito - if data was entered incorrectly, empty, etc. \n",
    "\n",
    "### TODO:  still losing some files after merging using this option - why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_ich.to_csv(\"ribbit_scores_with_verified_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of getting top scores for each wetland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable of all ichaway wetlands that had audio loggers \n",
    "ichaway_wetlands = verified_ich['site'].unique()\n",
    "\n",
    "# Get top 3 audio files for each wetland and save it to a csv file\n",
    "temp = get_top_rs(verified_ich, n = 3, group_col = 'site', groups = ichaway_wetlands, save_csv = \"./example_top_rs_ichaway.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSoundscape060",
   "language": "python",
   "name": "opensoundscape060"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
